{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szLQzYt2rRN5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import ViTImageProcessor, AutoTokenizer, VisionEncoderDecoderModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "ENCODER_ID = \"google/vit-base-patch16-224-in21k\"\n",
        "DECODER_ID = \"gpt2\"\n",
        "TOKENIZER_NAME = \"gpt2\"\n",
        "MODEL_PATH = r'./image-captioning-model/epoch_decoder_only_baseline_3'\n",
        "\n",
        "MAX_LEN = 48\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "jTLrA0ngrT2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup image preprocessor and tokenizer\n",
        "img_processor = ViTImageProcessor.from_pretrained(ENCODER_ID)\n",
        "cap_tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
        "cap_tokenizer.add_special_tokens({'pad_token': '<PAD>', 'bos_token': '<BOS>'})"
      ],
      "metadata": {
        "id": "0a0f6N42rVeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load saved model\n",
        "model = VisionEncoderDecoderModel.from_pretrained(MODEL_PATH)\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "id": "xchBgYHOrZDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image and pre-processing\n",
        "image_path = r\"./Flicker8k_images/667626_18933d713e.jpg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "pixel_values = img_processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "pixel_values = pixel_values.to(DEVICE)\n",
        "pixel_values.shape"
      ],
      "metadata": {
        "id": "lROtrY5TrbI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output_ids = model.generate(pixel_values, max_length=16, num_beams=4)\n",
        "generated_ids = model.generate(\n",
        "                  pixel_values=pixel_values,\n",
        "                  decoder_start_token_id=cap_tokenizer.bos_token_id,\n",
        "                  pad_token_id=cap_tokenizer.pad_token_id,\n",
        "                  eos_token_id=cap_tokenizer.eos_token_id,\n",
        "                  max_new_tokens=20,\n",
        "                  do_sample=True,\n",
        "                  top_p=0.9,\n",
        "                  temperature=0.7,\n",
        "                  #num_beams=5,\n",
        "                  #length_penalty=3.0,\n",
        "                  repetition_penalty=3.0,\n",
        "                  min_length=5,\n",
        "                  early_stopping=True\n",
        "              )\n",
        "preds = cap_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "print()\n",
        "print('====================================')\n",
        "print('=========== image caption ==========\\n')\n",
        "print(preds)"
      ],
      "metadata": {
        "id": "Kgp9t6xcrdgu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
