{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Model Robustness Experiments (with BLEU Scores)\n",
        "\n",
        "This notebook runs robustness experiments to test the baseline model performance under various image corruptions.\n",
        "\n",
        "**Tests:**\n",
        "- Baseline performance (no corruption)\n",
        "- All 11 corruption types (Gaussian noise, shot noise, impulse noise, defocus blur, motion blur, zoom blur, brightness, contrast, JPEG compression, pixelate, elastic transform)\n",
        "- 3 severity levels (1, 3, 5) for each corruption\n",
        "\n",
        "**Output:**\n",
        "- Results summary (console) with Loss and BLEU scores\n",
        "- JSON results file (includes all BLEU metrics)\n",
        "- Visualization plots (loss and BLEU-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "mount failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2093664811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ===== SETUP =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/GTech\\\\ OMSCS/CS\\\\ 7643/group\\\\ project/CS7643_project'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "# setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/GTech\\ OMSCS/CS\\ 7643/group\\ project/CS7643_project\n",
        "\n",
        "import sys\n",
        "import os\n",
        "project_root = '/content/drive/MyDrive/GTech OMSCS/CS 7643/group project/CS7643_project'\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "%pip install nltk -q\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model config\n",
        "MODEL_PATH = './epoch_decoder_only_baseline_3'\n",
        "\n",
        "# Dataset config\n",
        "DATASET_NAME = 'flickr8k'  # 'flickr8k' or 'flickr30k'\n",
        "SPLIT = 'test'  # 'test' or 'dev'\n",
        "\n",
        "# Experiment config\n",
        "OUTPUT_DIR = './robustness_results/baseline'\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 48\n",
        "\n",
        "# Corruption config\n",
        "SEVERITY_LEVELS = [1, 3, 5]\n",
        "\n",
        "# Device\n",
        "import torch\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Robustness Experiments\n",
        "\n",
        "This will:\n",
        "1. Load the model\n",
        "2. Test baseline performance (no corruption)\n",
        "3. Test all 11 corruption types at 3 severity levels each (33 corruption tests total)\n",
        "4. Calculate Loss and BLEU scores (BLEU-1, BLEU-2, BLEU-3, BLEU-4)\n",
        "5. Generate results and visualizations\n",
        "\n",
        "Results are automatically saved after each corruption type.\n",
        "\n",
        "**Checkpoint file:** `{OUTPUT_DIR}/checkpoint_{DATASET_NAME}_{SPLIT}.json`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from robustness.run_baseline_robustness import run_baseline_robustness_experiments\n",
        "import os\n",
        "\n",
        "checkpoint_file = os.path.join(OUTPUT_DIR, f'checkpoint_{DATASET_NAME}_{SPLIT}.json')\n",
        "if os.path.exists(checkpoint_file):\n",
        "    print(f\"âœ“ Found checkpoint: {checkpoint_file}\")\n",
        "    print(\"Resuming from checkpoint...\")\n",
        "else:\n",
        "    print(\"Starting new experiment...\")\n",
        "\n",
        "# Run experiments (automatically resumes from checkpoint if exists)\n",
        "results = run_baseline_robustness_experiments(\n",
        "    model_path=MODEL_PATH,\n",
        "    dataset_name=DATASET_NAME,\n",
        "    split=SPLIT,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    corruption_types=None,\n",
        "    severity_levels=SEVERITY_LEVELS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    max_len=MAX_LEN,\n",
        "    device=DEVICE,\n",
        "    base_dir='./'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Results\n",
        "\n",
        "The results have been saved to:\n",
        "- JSON file: `{OUTPUT_DIR}/baseline_robustness_{DATASET_NAME}_{SPLIT}.json`\n",
        "- Loss plot: `{OUTPUT_DIR}/robustness_loss_{DATASET_NAME}_{SPLIT}.png`\n",
        "- BLEU-4 plot: `{OUTPUT_DIR}/robustness_bleu4_{DATASET_NAME}_{SPLIT}.png`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'baseline' in results:\n",
        "    baseline = results['baseline']\n",
        "    print(\"Baseline Performance (No Corruption):\")\n",
        "    print(f\"  Loss: {baseline.get('loss', 'N/A'):.4f}\")\n",
        "    if 'metrics' in baseline:\n",
        "        metrics = baseline['metrics']\n",
        "        print(f\"\\nBLEU Scores:\")\n",
        "        print(f\"  BLEU-1: {metrics.get('bleu_1', 0):.4f}\")\n",
        "        print(f\"  BLEU-2: {metrics.get('bleu_2', 0):.4f}\")\n",
        "        print(f\"  BLEU-3: {metrics.get('bleu_3', 0):.4f}\")\n",
        "        print(f\"  BLEU-4: {metrics.get('bleu_4', 0):.4f}\")\n",
        "        print(f\"\\nCaption Lengths:\")\n",
        "        print(f\"  Avg Prediction: {metrics.get('avg_pred_length', 0):.2f} tokens\")\n",
        "        print(f\"  Avg Reference: {metrics.get('avg_ref_length', 0):.2f} tokens\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
